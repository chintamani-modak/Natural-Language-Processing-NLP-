{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESCRIPTION:\n",
    "\n",
    "Using NLP and ML, make a model to identify hate speech (racist or sexist tweets) in Twitter.\n",
    "\n",
    "Problem Statement:  \n",
    "\n",
    "Twitter is the biggest platform where anybody and everybody can have their views heard. Some of these voices spread hate and negativity. Twitter is wary of its platform being used as a medium  to spread hate. \n",
    "\n",
    "You are a data scientist at Twitter, and you will help Twitter in identifying the tweets with hate speech and removing them from the platform. You will use NLP techniques, perform specific cleanup for tweets data, and make a robust model.\n",
    "\n",
    "Domain: Social Media\n",
    "\n",
    "Analysis to be done: \n",
    "- Clean up tweets and build a classification model by using NLP techniques, \n",
    "- cleanup specific for tweets data\n",
    "- Regularization and hyperparameter tuning using stratified k-fold and cross validation to get the best model.\n",
    "\n",
    "Content: \n",
    "\n",
    "id: identifier number of the tweet , \n",
    "Label: 0 (non-hate) /1 (hate) ,\n",
    "Tweet: the text in the tweet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Load necessary libraries & Load the tweets file using read_csv function from Pandas Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0   @user when a father is dysfunctional and is s...\n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0  #model   i love u take with u all the time in ...\n",
       "4          5      0             factsguide: society now    #motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961  31962      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "inp_tweets0=pd.read_csv('TwitterHate.csv')\n",
    "inp_tweets0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Check the distribution of the label and find out if there is any class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.929854\n",
       "1    0.070146\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_tweets0.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above. we can clearly see that there is high imbalance in the classes.% non hate labels significantly higher than % hate labels. The modelling process will have to account for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Get the tweets into a list for easy text cleanup and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets0 = inp_tweets0.tweet.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 :  Cleanup \n",
    "\n",
    "- Normalize the case\n",
    "- Using regular expressions, remove user handles. These begin with '@’\n",
    "- Using regular expressions, remove URLs\n",
    "- Using TweetTokenizer from NLTK, tokenize the tweets into individual terms\n",
    "- Remove stop words\n",
    "- Remove redundant terms like ‘amp’, ‘rt’, etc\n",
    "- Remove ‘#’ symbols from the tweet while retaining the term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the case\n",
    "tweets0_lower = [twt.lower() for twt in tweets0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' this course rocks! http://rahimbaig.com/ai'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing user handles\n",
    "# Testing on a test string\n",
    "\n",
    "import re\n",
    "re.sub(\"@\\w+\",\"\",\"@Rahim this course rocks! http://rahimbaig.com/ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying on the data \n",
    "tweets0_nouser = [re.sub(\"@\\w+\",\"\",twt)for twt in tweets0_lower]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@Rahim this course rocks! '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing URLs\n",
    "# Test string example\n",
    "re.sub(\"\\w+://\\S+\",\"\", \"@Rahim this course rocks! http://rahimbaig.com/ai\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying on the data\n",
    "tweets_nourl = [re.sub(\"\\w+://\\S+\",\"\", twt) for twt in tweets0_nouser] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing isong TweetTokenizer from NLTK\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tkn = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when', 'a', 'father', 'is', 'dysfunctional', 'and', 'is', 'so', 'selfish', 'he', 'drags', 'his', 'kids', 'into', 'his', 'dysfunction', '.', '#run']\n"
     ]
    }
   ],
   "source": [
    "# Applying the tokenizer on the data using list comprehension\n",
    "tweet_token = [tkn.tokenize(sent) for sent in tweets_nourl]\n",
    "print(tweet_token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation, stop words, redundant terms like 'rt', 'amp' and removing terms with length of 1\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_nltk = stopwords.words(\"english\") \n",
    "\n",
    "stop_punct = list(punctuation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding some specific punctuation from the data\n",
    "stop_punct.extend(['...','``',\"''\",\"..\"])\n",
    "\n",
    "stop_context = ['rt','amp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final stop word list including all of these:\n",
    "stop_final = stop_nltk + stop_punct + stop_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to:\n",
    "# a. Remove stopwords from a single tokenized sentence\n",
    "# b. Remove # tags\n",
    "# c. Remove terms with length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_stop(sent):\n",
    "    return [re.sub(\"#\",\"\",term) for term in sent if ((term not in stop_final) & (len(term)>1))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying function on the data \n",
    "tweets_clean = [del_stop(tweet) for tweet in tweet_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['father', 'dysfunctional', 'selfish', 'drags', 'kids', 'dysfunction', 'run']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_clean[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 Check out the top terms in the tweets. \n",
    "\n",
    "- First, get all the tokenized terms into one large list\n",
    "- Use counter and find the 10 most common terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 2748),\n",
       " ('day', 2276),\n",
       " ('happy', 1684),\n",
       " ('time', 1131),\n",
       " ('life', 1118),\n",
       " ('like', 1047),\n",
       " (\"i'm\", 1018),\n",
       " ('today', 1013),\n",
       " ('new', 994),\n",
       " ('thankful', 946)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding all terms to one huge list\n",
    "terms_list = []\n",
    "for tweet in tweets_clean:\n",
    "    terms_list.extend(tweet)\n",
    "    \n",
    "# Using counter to get top terms:\n",
    "from collections import Counter\n",
    "res = Counter(terms_list)\n",
    "res.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6  Data formatting for predictive modeling:\n",
    "\n",
    "- Join the tokens back to form strings. This will be required for the vectorizers\n",
    "- Assign x and y\n",
    "- Perform train_test_split using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join tokens back to form strings. This will be required for the vectorizers.\n",
    "\n",
    "tweets_clean = [\"\".join(tweet) for tweet in tweets_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X and y\n",
    "\n",
    "X = tweets_clean\n",
    "y = inp_tweets0.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train_test_split using scikit learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 Use TF-IDF values for the terms as a feature to get into a vector space model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and apply on the train set\n",
    "X_train_bow = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22373, 5000), (9589, 5000))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply on the test set\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "X_train_bow.shape,X_test_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task  8 Model building: Ordinary Logistic Regression\n",
    "\n",
    "- Instantiate Logistic Regression from sklearn with default parameters.\n",
    "- Fit into  the train data.\n",
    "- Make predictions for the train and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting on the train data\n",
    "logreg.fit(X_train_bow,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_train_pred = logreg.predict(X_train_bow)\n",
    "y_test_pred = logreg.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9 Model Evaluation: Accuracy, recall, and f1_score \n",
    "\n",
    "- Report the accuracy on the train set\n",
    "- Report the recall on the train set:decent, high, or low? \n",
    "- Get the f1_score on the train set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9362177624815626"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the accuracy score\n",
    "accuracy_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "93.6% accuracy may not be good if we are not capturing the 1s well at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     20815\n",
      "           1       1.00      0.08      0.16      1558\n",
      "\n",
      "    accuracy                           0.94     22373\n",
      "   macro avg       0.97      0.54      0.56     22373\n",
      "weighted avg       0.94      0.94      0.91     22373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now lets look at classification report\n",
    "print(classification_report(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall is just 8% for 1 class which is not good at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10 From the above it gets clear that we will need to adjust the class imblance as the model seem,s to focus too much on 0s\n",
    "  - a) Adjust the appropriate class in the LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11 Train again with the adjustment and evaluate.\n",
    "\n",
    "- Train the model on the train set\n",
    "- Evaluate the predictions on the train set: accuracy, recall, and f_1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_bow,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the train set\n",
    "y_train_pred = logreg.predict(X_train_bow)\n",
    "y_test_pred =  logreg.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9544540294104501"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     20815\n",
      "           1       0.88      0.40      0.55      1558\n",
      "\n",
      "    accuracy                           0.95     22373\n",
      "   macro avg       0.92      0.70      0.76     22373\n",
      "weighted avg       0.95      0.95      0.95     22373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now lets look at classification report\n",
    "print(classification_report(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better on the train set ! A recall of 40% which has improved from 8%. f1_Score has got better at 55%\n",
    "This is still on the training data. The performance could be lower on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12 Regularization and Hyperparameter tuning:\n",
    "\n",
    "- Import GridSearch and StratifiedKFold because of class imbalance\n",
    "- Provide the parameter grid to choose for ‘C’ and ‘penalty’ parameters\n",
    "- Use a balanced class weight while instantiating the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'C': [0.01,0.1,1,10,100],\n",
    "    'penalty': [\"l1\",\"l2\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_lr = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 13 Find the parameters with the best recall in cross validation.\n",
    "\n",
    "- Choose ‘recall’ as the metric for scoring.\n",
    "- Choose stratified 4 fold cross validation scheme.\n",
    "- Fit into  the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=classifier_lr,param_grid = param_grid,\n",
    "              cv = StratifiedKFold(4), n_jobs=-1, verbose=1, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(class_weight='balanced'), n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']},\n",
       "             scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting gridsearch on training data\n",
    "grid_search.fit(X_train_bow,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 14 What are the best parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 15 Predict and evaluate using the best estimator\n",
    "- Use the best estimator from the grid search to make predictions on the test set\n",
    "- What is the recall on the test set for the toxic comments?\n",
    "- What is the f_1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      8905\n",
      "           1       0.72      0.15      0.25       684\n",
      "\n",
      "    accuracy                           0.94      9589\n",
      "   macro avg       0.83      0.57      0.61      9589\n",
      "weighted avg       0.92      0.94      0.91      9589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = grid_search.best_estimator_.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1-score for class 1 is 0.25 and recall as 0.15\n",
    "As compared to grid search, LogisticRegression method gave us better recall and f1-score after doing class-weight='balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
